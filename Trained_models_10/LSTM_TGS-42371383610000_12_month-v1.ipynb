{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import keras\n",
    "import argparse\n",
    "import scipy.io\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.regularizers import L1L2\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/affine/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (7,20,23,25,34,48,65,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "master_data= pd.read_csv('/home/affine/Downloads/Deep_Learning/demo/demo/TGS/tgs-data-science-master-c3f8b3a2900f40ddde655f8ef5f17d00cfaa7033/data/Master_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'WellId', 'LeaseId', 'GroupId', 'API', 'FieldName_x',\n",
       "       'Well Name and Number', 'WellNumber_x', 'OperatorName_x', 'StateName_x',\n",
       "       'County_x', 'ProductionMonthYear', 'DaysOnProduction', 'Gas', 'Oil',\n",
       "       'Water', 'ProductionType', 'ProductionTypeName', 'WellsReported',\n",
       "       'AllocationMethod', 'DisplayFormation_x', 'StateLeaseId', 'WellName',\n",
       "       'WellNumber_y', 'BasinName', 'DisplayFormation_y', 'Township',\n",
       "       'TownshipDirection', 'Range', 'RangeDirection', 'Section', 'District',\n",
       "       'Abstract', 'Survey', 'Block', 'Offshore', 'Area', 'OffshoreBlock',\n",
       "       'QuarterQuarter', 'FootageNS', 'DirectionNS', 'FootageEW',\n",
       "       'DirectionEW', 'SurfaceLatitude', 'SurfaceLongitude', 'BottomLatitude',\n",
       "       'BottomLongitude', 'SpudDate', 'PlugDate', 'CompletionDate',\n",
       "       'FirstProductionDate', 'FirstMonth', 'HasProduction', 'WellType',\n",
       "       'TotalVerticalDepth', 'MeasuredDepth', 'ElevationGround',\n",
       "       'ElevationKellyBushing', 'ElevationWaterDepth', 'WellStatus',\n",
       "       'CurrentLeaseName', 'CalculatedMajorPhase', 'DisplayLocation', 'Slant',\n",
       "       'HasWellProduction', 'LocationDescription', 'MeridianName',\n",
       "       'SymbolName', 'MeridianId', 'APIState', 'APICounty', 'DisplayElevation',\n",
       "       'StateWellID', 'Top', 'Bottom', 'ProductionMonthYear1', 'YearMonth',\n",
       "       'unique', 'Oil_test', 'Gas_test', 'Water_test', 'GOR', 'TestDuration',\n",
       "       'Method', 'CasingPressure', 'ShutInPressure', 'GasGravity',\n",
       "       'OilGravity', 'FTP', 'WellID_API'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns in dataset\n",
    "master_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting Operator 'Occidental W TX OVERTHRUST INC.'\n",
    "master_data1=master_data[master_data.OperatorName_x==\"OCCIDENTAL W TX OVERTHRUST INC.\"]\n",
    "#master_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select required API\n",
    "master_data1=master_data1[master_data1.API==42371383610000]#42371380040000]#42371381890000]#42371381890000]#42371378930000]\n",
    "labels=['Oil','ProductionMonthYear1','YearMonth']\n",
    "master_data1=master_data1[labels]\n",
    "\n",
    "#Sort data based on YearMonth\n",
    "master_data1=master_data1.sort_values(by=['YearMonth'])#, ascending=[1, 1],axis=1)\n",
    "#master_data1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data2=master_data1\n",
    "master_data2=pd.DataFrame(master_data2)\n",
    "# master_data2['start_date']=datetime.strptime(master_data1['ProductionMonthYear1'].iloc[0], \"%Y-%m-%d\")\n",
    "# print(type(pd.DataFrame(master_data2['start_date']).iloc[0,0]))\n",
    "# print(type(pd.DataFrame(master_data2['ProductionMonthYear1']).iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_data2['ProductionMonthYear1']=master_data2['ProductionMonthYear1'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "# master_data2['days_age']=master_data2['ProductionMonthYear1'].sub(master_data2['start_date'])\n",
    "# master_data2['days_age']=master_data2['days_age']/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oil</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearMonth</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200810</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200811</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200812</th>\n",
       "      <td>659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200901</th>\n",
       "      <td>412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200902</th>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200903</th>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200904</th>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200905</th>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200906</th>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200907</th>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200908</th>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200909</th>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200910</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200911</th>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200912</th>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001</th>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201002</th>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201003</th>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201004</th>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201005</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201006</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201007</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201008</th>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201009</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201010</th>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201011</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201012</th>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101</th>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201102</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201103</th>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201412</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201501</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201502</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201503</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201504</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201505</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201506</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201507</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201508</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201509</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201510</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201511</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201512</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201607</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201608</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201610</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201702</th>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201703</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201704</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201705</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Oil\n",
       "YearMonth       \n",
       "200810       0.0\n",
       "200811       0.0\n",
       "200812     659.0\n",
       "200901     412.0\n",
       "200902     215.0\n",
       "200903     220.0\n",
       "200904     135.0\n",
       "200905      99.0\n",
       "200906     112.0\n",
       "200907     124.0\n",
       "200908     149.0\n",
       "200909     102.0\n",
       "200910      81.0\n",
       "200911     129.0\n",
       "200912      61.0\n",
       "201001     123.0\n",
       "201002      77.0\n",
       "201003      44.0\n",
       "201004     102.0\n",
       "201005      31.0\n",
       "201006      72.0\n",
       "201007      70.0\n",
       "201008      68.0\n",
       "201009      63.0\n",
       "201010      50.0\n",
       "201011      10.0\n",
       "201012      60.0\n",
       "201101      58.0\n",
       "201102      31.0\n",
       "201103      54.0\n",
       "...          ...\n",
       "201412      22.0\n",
       "201501      28.0\n",
       "201502      22.0\n",
       "201503       0.0\n",
       "201504       0.0\n",
       "201505       3.0\n",
       "201506      10.0\n",
       "201507      24.0\n",
       "201508      11.0\n",
       "201509      27.0\n",
       "201510       1.0\n",
       "201511      10.0\n",
       "201512      23.0\n",
       "201601      24.0\n",
       "201602      13.0\n",
       "201603      20.0\n",
       "201604      15.0\n",
       "201605      24.0\n",
       "201606      22.0\n",
       "201607       6.0\n",
       "201608      27.0\n",
       "201609      21.0\n",
       "201610      11.0\n",
       "201611       0.0\n",
       "201612      18.0\n",
       "201701      21.0\n",
       "201702      16.0\n",
       "201703      30.0\n",
       "201704      15.0\n",
       "201705      21.0\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set YearMonth as Index for production\n",
    "master_data2=master_data2[['YearMonth','Oil']]#,'days_age']]\n",
    "master_data2=master_data2.iloc[:-1,:]# removing 201708 & 201709 values as they were zeros\n",
    "master_data2.set_index('YearMonth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3aef142b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataset = master_data2\n",
    "values = dataset.values\n",
    "\n",
    "# specify columns to plot\n",
    "groups = [0,1]#,2]#3,4]#,5,6,7,8,9,10]\n",
    "i = 0\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i+1)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define lag(time steps for training) and n_seq(number of time steps to be predicted in future)\n",
    "n_seq = 12\n",
    "n_feature=1\n",
    "n_lag= 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 1)\n",
      "    var1(t-24)  var1(t-23)  var1(t-22)  var1(t-21)  var1(t-20)  var1(t-19)  \\\n",
      "24    0.000000    0.000000    1.000000    0.625190    0.326252    0.333839   \n",
      "25    0.000000    1.000000    0.625190    0.326252    0.333839    0.204856   \n",
      "26    1.000000    0.625190    0.326252    0.333839    0.204856    0.150228   \n",
      "27    0.625190    0.326252    0.333839    0.204856    0.150228    0.169954   \n",
      "28    0.326252    0.333839    0.204856    0.150228    0.169954    0.188164   \n",
      "\n",
      "    var1(t-18)  var1(t-17)  var1(t-16)  var1(t-15)     ...      var1(t+2)  \\\n",
      "24    0.204856    0.150228    0.169954    0.188164     ...       0.091047   \n",
      "25    0.150228    0.169954    0.188164    0.226100     ...       0.088012   \n",
      "26    0.169954    0.188164    0.226100    0.154780     ...       0.047041   \n",
      "27    0.188164    0.226100    0.154780    0.122914     ...       0.081942   \n",
      "28    0.226100    0.154780    0.122914    0.195751     ...       0.068285   \n",
      "\n",
      "    var1(t+3)  var1(t+4)  var1(t+5)  var1(t+6)  var1(t+7)  var1(t+8)  \\\n",
      "24   0.088012   0.047041   0.081942   0.068285   0.072838   0.037936   \n",
      "25   0.047041   0.081942   0.068285   0.072838   0.037936   0.022762   \n",
      "26   0.081942   0.068285   0.072838   0.037936   0.022762   0.054628   \n",
      "27   0.068285   0.072838   0.037936   0.022762   0.054628   0.062215   \n",
      "28   0.072838   0.037936   0.022762   0.054628   0.062215   0.063733   \n",
      "\n",
      "    var1(t+9)  var1(t+10)  var1(t+11)  \n",
      "24   0.022762    0.054628    0.062215  \n",
      "25   0.054628    0.062215    0.063733  \n",
      "26   0.062215    0.063733    0.059181  \n",
      "27   0.063733    0.059181    0.056146  \n",
      "28   0.059181    0.056146    0.063733  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "(69, 36)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = master_data2.iloc[:,1:]\n",
    "values = dataset.values\n",
    "print(values.shape)\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "#print(values)\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_lag, n_seq)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "# reframed.drop(reframed.iloc[:,25:], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 24, 1) (68, 12) (1, 24, 1) (1, 12)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "train = values[:-1, :]\n",
    "test = values[-1:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-(n_seq)], train[:, -(n_seq):]\n",
    "test_X, test_y = test[:, :-n_seq], test[:, -n_seq:]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], train_X.shape[1], n_feature))\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[1], n_feature))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "h1=n_lag*2\n",
    "h2=n_lag*2\n",
    "h3=n_seq\n",
    "h4=n_seq\n",
    "drop1=0.4\n",
    "drop2=0.3\n",
    "drop3=0.0 \n",
    "drop4=0.0\n",
    "n_y=n_seq\n",
    "epoch=1000\n",
    "batch_size=16\n",
    "lr=0.0003\n",
    "L1=0.00\n",
    "L2=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(LSTM(h1, batch_input_shape=(batch_size,train_X.shape[1],train_X.shape[2]), stateful=True))#,return_sequences=True, recurrent_regularizer=reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "reg = L1L2(l1=L1, l2=L2)\n",
    "model.add(LSTM(h1, input_shape=(train_X.shape[1],train_X.shape[2]),return_sequences=True, recurrent_regularizer=reg))\n",
    "model.add(Dropout(drop1, seed = 1))\n",
    "model.add(LSTM(h2,return_sequences=True))\n",
    "model.add(Dropout(drop2, seed = 1))\n",
    "model.add(LSTM(h3,return_sequences=True))\n",
    "model.add(Dropout(drop3, seed = 1))\n",
    "model.add(LSTM(h4,return_sequences=False))\n",
    "model.add(Dropout(drop4, seed = 1))\n",
    "model.add(Dense(n_seq, activation='relu'))\n",
    "model.add(Dense(n_y, activation='relu'))\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mae', optimizer= adam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=load_model('LSTM_12_month.h5')\n",
    "# weights=model.get_weights()\n",
    "# print(weights)\n",
    "# model.save_weights('weights.hdf5')\n",
    "# model.set_weights(weights)\n",
    "# model.load_weights('weights.hdf5')\n",
    "# model.load_weights('weights_42371381890000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 1 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 0.5087 - val_loss: 0.4845\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.4888 - val_loss: 0.4652\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.4713 - val_loss: 0.4486\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.4553 - val_loss: 0.4335\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.4397 - val_loss: 0.4187\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.4251 - val_loss: 0.4045\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.4114 - val_loss: 0.3912\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.3981 - val_loss: 0.3784\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.3852 - val_loss: 0.3661\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.3729 - val_loss: 0.3538\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.3608 - val_loss: 0.3416\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.3491 - val_loss: 0.3300\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.3379 - val_loss: 0.3189\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.3273 - val_loss: 0.3084\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.3170 - val_loss: 0.2987\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.3071 - val_loss: 0.2897\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.2974 - val_loss: 0.2808\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.2883 - val_loss: 0.2721\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.2794 - val_loss: 0.2638\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.2709 - val_loss: 0.2558\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.2626 - val_loss: 0.2482\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.2548 - val_loss: 0.2406\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.2472 - val_loss: 0.2331\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.2396 - val_loss: 0.2259\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.2325 - val_loss: 0.2193\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.2257 - val_loss: 0.2127\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.2190 - val_loss: 0.2057\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.2126 - val_loss: 0.1997\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.2062 - val_loss: 0.1938\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.2002 - val_loss: 0.1878\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.1944 - val_loss: 0.1818\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.1888 - val_loss: 0.1765\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.1834 - val_loss: 0.1714\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.1781 - val_loss: 0.1661\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.1730 - val_loss: 0.1612\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.1680 - val_loss: 0.1564\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.1632 - val_loss: 0.1515\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.1585 - val_loss: 0.1471\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.1541 - val_loss: 0.1429\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.1498 - val_loss: 0.1387\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.1457 - val_loss: 0.1347\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.1416 - val_loss: 0.1305\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.1377 - val_loss: 0.1265\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.1338 - val_loss: 0.1230\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.1302 - val_loss: 0.1193\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.1266 - val_loss: 0.1155\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.1231 - val_loss: 0.1123\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.1198 - val_loss: 0.1093\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.1165 - val_loss: 0.1061\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.1135 - val_loss: 0.1031\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.1104 - val_loss: 0.1003\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.1074 - val_loss: 0.0972\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.1045 - val_loss: 0.0945\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.1019 - val_loss: 0.0921\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.0992 - val_loss: 0.0893\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.0968 - val_loss: 0.0866\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.0941 - val_loss: 0.0841\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.0917 - val_loss: 0.0821\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.0894 - val_loss: 0.0795\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.0871 - val_loss: 0.0774\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.0850 - val_loss: 0.0756\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.0828 - val_loss: 0.0733\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.0807 - val_loss: 0.0715\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.0787 - val_loss: 0.0697\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.0769 - val_loss: 0.0676\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.0750 - val_loss: 0.0659\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.0731 - val_loss: 0.0643\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.0715 - val_loss: 0.0620\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.0698 - val_loss: 0.0606\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.0680 - val_loss: 0.0594\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.0666 - val_loss: 0.0575\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.0649 - val_loss: 0.0559\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.0634 - val_loss: 0.0549\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.0621 - val_loss: 0.0531\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.0606 - val_loss: 0.0520\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.0592 - val_loss: 0.0509\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.0580 - val_loss: 0.0494\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.0567 - val_loss: 0.0481\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.0554 - val_loss: 0.0473\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.0542 - val_loss: 0.0463\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.0531 - val_loss: 0.0451\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.0520 - val_loss: 0.0433\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.0509 - val_loss: 0.0425\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.0498 - val_loss: 0.0424\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.0488 - val_loss: 0.0409\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.0478 - val_loss: 0.0402\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.0466 - val_loss: 0.0413\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.0456 - val_loss: 0.0398\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.0444 - val_loss: 0.0383\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.0432 - val_loss: 0.0382\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.0419 - val_loss: 0.0377\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.0407 - val_loss: 0.0370\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.0396 - val_loss: 0.0372\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.0384 - val_loss: 0.0371\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.0376 - val_loss: 0.0359\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.0369 - val_loss: 0.0350\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.0360 - val_loss: 0.0354\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.0354 - val_loss: 0.0341\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.0347 - val_loss: 0.0334\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.0339 - val_loss: 0.0333\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.0333 - val_loss: 0.0320\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.0328 - val_loss: 0.0318\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.0322 - val_loss: 0.0319\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.0316 - val_loss: 0.0303\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.0310 - val_loss: 0.0299\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.0304 - val_loss: 0.0301\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.0300 - val_loss: 0.0290\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.0295 - val_loss: 0.0284\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.0289 - val_loss: 0.0287\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0277\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.0281 - val_loss: 0.0273\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.0276 - val_loss: 0.0271\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.0272 - val_loss: 0.0268\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.0268 - val_loss: 0.0268\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.0261 - val_loss: 0.0256\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.0256 - val_loss: 0.0253\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.0253 - val_loss: 0.0246\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.0250 - val_loss: 0.0247\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.0246 - val_loss: 0.0242\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.0240 - val_loss: 0.0239\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.0236 - val_loss: 0.0230\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.0234 - val_loss: 0.0231\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.0230 - val_loss: 0.0230\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.0228 - val_loss: 0.0224\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.0224 - val_loss: 0.0229\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.0223 - val_loss: 0.0220\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.0220 - val_loss: 0.0214\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.0218 - val_loss: 0.0224\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.0214 - val_loss: 0.0210\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.0206 - val_loss: 0.0203\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.0205 - val_loss: 0.0200\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.0201 - val_loss: 0.0204\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.0199 - val_loss: 0.0200\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.0196 - val_loss: 0.0194\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.0193 - val_loss: 0.0191\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.0191 - val_loss: 0.0186\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.0190 - val_loss: 0.0186\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.0188 - val_loss: 0.0186\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.0186 - val_loss: 0.0186\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.0185 - val_loss: 0.0183\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.0183 - val_loss: 0.0184\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.0183 - val_loss: 0.0183\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0181 - val_loss: 0.0182\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.0180 - val_loss: 0.0177\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.0179 - val_loss: 0.0179\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.0178 - val_loss: 0.0179\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.0177 - val_loss: 0.0174\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.0175 - val_loss: 0.0178\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.0172 - val_loss: 0.0171\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.0169 - val_loss: 0.0175\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.0169 - val_loss: 0.0169\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.0169 - val_loss: 0.0168\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.0166 - val_loss: 0.0163\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.0165 - val_loss: 0.0173\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.0164 - val_loss: 0.0166\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.0163 - val_loss: 0.0166\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.0162 - val_loss: 0.0164\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.0161 - val_loss: 0.0158\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.0159 - val_loss: 0.0165\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.0158 - val_loss: 0.0158\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.0158 - val_loss: 0.0161\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.0156 - val_loss: 0.0160\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.0156 - val_loss: 0.0163\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.0155 - val_loss: 0.0156\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.0155 - val_loss: 0.0159\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.0155 - val_loss: 0.0155\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.0154 - val_loss: 0.0157\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.0153 - val_loss: 0.0155\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.0152 - val_loss: 0.0156\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.0151 - val_loss: 0.0159\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.0151 - val_loss: 0.0152\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.0151 - val_loss: 0.0153\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.0150 - val_loss: 0.0154\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0153\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0152\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0154\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0153\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.0148 - val_loss: 0.0154\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0157\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0153\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0153\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0154\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0144\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0151\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.0145 - val_loss: 0.0146\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0147\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0147\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0152\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0150\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0148\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0148\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0137\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0144\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0143\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0142\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0138\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0142\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0140\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0137\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0136\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0129\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.0138 - val_loss: 0.0134\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 332/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0131\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0132\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0126\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0124\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 496/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0124\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0122\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0123\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0136\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0130\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0133\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0130\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0134\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0131\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0137\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0129\n",
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0128\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0136\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0129\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0129\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0130\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0124\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0127\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0137\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0137\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0128\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0137\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0137\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0126\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0134\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0135 - val_loss: 0.0126\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0127\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0132\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0131\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0138\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0132 - val_loss: 0.0133\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3aef77470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs = epoch, batch_size = batch_size, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# model.save('LSTM_12_month_42371381890000.h5')\n",
    "# del model\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE MODEL\n",
    "\n",
    "model.save('LSTM_12_month_42371383610000_v2.h5')\n",
    "# model=load_model('LSTM_12_month_42371383610000.h5')\n",
    "# weights=model.get_weights()\n",
    "# print(weights)\n",
    "model.save_weights('weights_42371383610000_v2.hdf5')\n",
    "# model.set_weights(weights)\n",
    "# weights=model.load_weights('weights_42371383610000.hdf5')\n",
    "# model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10.370\n",
      "MAE = 8.78704\n"
     ]
    }
   ],
   "source": [
    "#Predict the model on test\n",
    "yhat = model.predict(test_X)\n",
    "# print(yhat.shape)\n",
    "# print(test_y.shape)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = scaler.inverse_transform(yhat)\n",
    "# print(inv_yhat.shape)\n",
    "inv_yhat = inv_yhat[:,:]\n",
    "\n",
    "# invert scaling for actual\n",
    "inv_y = scaler.inverse_transform(test_y)\n",
    "inv_y = inv_y[:,:]\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "#def mean_absolute_error(y_true, y_pred):\n",
    "MAE = mean_absolute_error(inv_y, inv_yhat)\n",
    "print(\"MAE = \"+str(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 12.445\n",
      "MAE Train = 8.68287\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on train\n",
    "yhat_train = model.predict(train_X)\n",
    "\n",
    "# invert scaling for train forecast\n",
    "inv_yhat_train = scaler.inverse_transform(yhat_train)\n",
    "\n",
    "# invert scaling for actual train\n",
    "inv_y_train = scaler.inverse_transform(train_y)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y_train, inv_yhat_train))\n",
    "print('Train RMSE: %.3f' % rmse)\n",
    "\n",
    "#def mean_absolute_error(y_true, y_pred):\n",
    "MAE_train = mean_absolute_error(inv_y_train, inv_yhat_train)\n",
    "print(\"MAE Train = \"+str(MAE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE Train = 1.51889\n",
      "MAPE Test = 1.50857\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mape\n",
    "# Note LSTM always gives 1 step shifted reponse\n",
    "\n",
    "#test Mape\n",
    "Mape_test1=[]\n",
    "for i in range(n_seq-1):\n",
    "    mape1=(np.abs(inv_y[:,i]-inv_yhat[:,i+1])/(inv_y[:,i]+1))\n",
    "    Mape_test1.append(mape1)\n",
    "#print(Mape_test1)\n",
    "Mape_test=np.mean(Mape_test1)\n",
    "\n",
    "#Mape_test=np.mean(np.abs(inv_y[i]-inv_yhat[i+1])/(inv_y[i]+1))\n",
    "#Mape_train=np.mean(np.abs(inv_y_train[i]-inv_yhat_train[i+1])/(inv_y_train[i]+1))\n",
    "Mape_train=np.mean(np.abs(inv_y_train-inv_yhat_train)/(inv_y_train+1))\n",
    "\n",
    "print(\"MAPE Train = \"+str(Mape_train))\n",
    "print(\"MAPE Test = \"+str(Mape_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3ac0a7160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1=pd.DataFrame(inv_y)\n",
    "df2=pd.DataFrame(inv_yhat)\n",
    "value1=df1.values\n",
    "value2=df2.values\n",
    "value1=value1.reshape(n_seq,1)\n",
    "value2=value2.reshape(n_seq,1)\n",
    "plt.figure()\n",
    "plt.plot(value1,'b')\n",
    "plt.plot(value2,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=pd.DataFrame(inv_y_train[0,:])\n",
    "# df2=pd.DataFrame(inv_yhat_train[0,:])\n",
    "# print(inv_y_train.shape)\n",
    "# value1=df1.values\n",
    "# value2=df2.values\n",
    "# value1=value1.reshape(n_seq,1)\n",
    "# value2=value2.reshape(n_seq,1)\n",
    "# plt.figure()\n",
    "# plt.plot(value1,'b')\n",
    "# plt.plot(value2,'r')\n",
    "# plt.show()\n",
    "\n",
    "# df1=pd.DataFrame(inv_y_train[20,:])\n",
    "# df2=pd.DataFrame(inv_yhat_train[20,:])\n",
    "# print(inv_y_train.shape)\n",
    "# value1=df1.values\n",
    "# value2=df2.values\n",
    "# value1=value1.reshape(n_seq,1)\n",
    "# value2=value2.reshape(n_seq,1)\n",
    "# plt.figure()\n",
    "# plt.plot(value1,'b')\n",
    "# plt.plot(value2,'r')\n",
    "# plt.show()\n",
    "\n",
    "# df1=pd.DataFrame(inv_y_train[40,:])\n",
    "# df2=pd.DataFrame(inv_yhat_train[40,:])\n",
    "# print(inv_y_train.shape)\n",
    "# value1=df1.values\n",
    "# value2=df2.values\n",
    "# value1=value1.reshape(n_seq,1)\n",
    "# value2=value2.reshape(n_seq,1)\n",
    "# plt.figure()\n",
    "# plt.plot(value1,'b')\n",
    "# plt.plot(value2,'r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0, 19.2523\n",
      "6.0, 20.692\n",
      "27.0, 19.7685\n",
      "21.0, 23.3217\n",
      "11.0, 21.2684\n",
      "0.0, 19.65\n",
      "18.0, 12.1798\n",
      "21.0, 16.5694\n",
      "16.0, 0.0\n",
      "30.0, 17.2625\n",
      "15.0, 20.286\n",
      "21.0, 16.7411\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inv_y)):\n",
    "    for j in range(len(inv_y[i])):\n",
    "        print(str(inv_y[i][j])+\", \"+str(inv_yhat[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YearMonth   Oil  Oil_Actual  Oil_Predicted\n",
      "0    201606.0  22.0        22.0      20.692011\n",
      "1    201607.0   6.0         6.0      19.768496\n",
      "2    201608.0  27.0        27.0      23.321663\n",
      "3    201609.0  21.0        21.0      21.268402\n",
      "4    201610.0  11.0        11.0      19.650007\n",
      "5    201611.0   0.0         0.0      12.179789\n",
      "6    201612.0  18.0        18.0      16.569386\n",
      "7    201701.0  21.0        21.0       0.000000\n",
      "8    201702.0  16.0        16.0      17.262547\n",
      "9    201703.0  30.0        30.0      20.285963\n",
      "10   201704.0  15.0        15.0      16.741087\n"
     ]
    }
   ],
   "source": [
    "# get test results in CSV\n",
    "df1=pd.DataFrame(inv_y[:,:-1])\n",
    "df1=pd.DataFrame.transpose(df1)\n",
    "df2=pd.DataFrame(inv_yhat[:,1:])\n",
    "df2=pd.DataFrame.transpose(df2)\n",
    "df3=pd.DataFrame(np.array(master_data2.iloc[-n_seq:-1,:]))\n",
    "df3.columns=['YearMonth','Oil']\n",
    "df4=pd.concat([df3,df1,df2],axis=1)\n",
    "df4.columns=['YearMonth','Oil','Oil_Actual','Oil_Predicted']\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('/home/affine/Downloads/Deep_Learning/demo/demo/TGS/Models/Outputs/API_42371383610000_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>Oil</th>\n",
       "      <th>Actual_Oil</th>\n",
       "      <th>Predicted_Oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201010.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.213772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201011.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>48.485497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201012.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>46.778873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201101.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>46.249847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201102.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.999998</td>\n",
       "      <td>45.558784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201103.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>44.792404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201104.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>44.010948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201105.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.000004</td>\n",
       "      <td>43.350960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201106.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>42.770569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201107.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.162395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201108.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>41.522270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201109.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>40.780415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201110.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>40.224487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>201111.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.765007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>201112.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.028496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>201201.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>38.704250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>201202.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>37.940010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201203.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>37.510075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>201204.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>37.354706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>201205.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>36.532761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>201206.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>36.555859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>201207.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.620247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>201208.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>34.071918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201209.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.294685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>201210.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>30.723692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>201211.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>29.887678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>201212.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.419239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>201301.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>29.918350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>201302.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>28.477352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>201303.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.999998</td>\n",
       "      <td>28.668974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>201403.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>22.800194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>201404.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.864763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>201405.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.299210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>201406.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>21.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>201407.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>22.521513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>201408.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.908621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>201409.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.097118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>201410.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.619822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>201411.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>19.952507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>201412.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.389376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>201501.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>19.385174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>201502.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>18.574678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>201503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.007071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>201504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.594421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>201505.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.132944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>201506.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.173548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>201507.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.000002</td>\n",
       "      <td>18.510143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>201508.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.580679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>201509.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>18.829767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>201510.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.294214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>201511.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.149229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>201512.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.108074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>201601.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.000002</td>\n",
       "      <td>18.585575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>201602.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.494240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>201603.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.937077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>201604.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.829069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>201605.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.000002</td>\n",
       "      <td>21.115686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>201606.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.408377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>201607.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.513691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>201608.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.052340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year-Month   Oil  Actual_Oil  Predicted_Oil\n",
       "0     201010.0  50.0   50.000000      50.213772\n",
       "1     201011.0  10.0   10.000000      48.485497\n",
       "2     201012.0  60.0   60.000000      46.778873\n",
       "3     201101.0  58.0   58.000000      46.249847\n",
       "4     201102.0  31.0   30.999998      45.558784\n",
       "5     201103.0  54.0   54.000000      44.792404\n",
       "6     201104.0  45.0   45.000000      44.010948\n",
       "7     201105.0  48.0   48.000004      43.350960\n",
       "8     201106.0  25.0   25.000000      42.770569\n",
       "9     201107.0  15.0   15.000000      42.162395\n",
       "10    201108.0  36.0   36.000000      41.522270\n",
       "11    201109.0  41.0   41.000000      40.780415\n",
       "12    201110.0  42.0   42.000000      40.224487\n",
       "13    201111.0  39.0   39.000000      39.765007\n",
       "14    201112.0  37.0   37.000000      39.028496\n",
       "15    201201.0  42.0   42.000000      38.704250\n",
       "16    201202.0  38.0   38.000000      37.940010\n",
       "17    201203.0  42.0   42.000000      37.510075\n",
       "18    201204.0  19.0   19.000000      37.354706\n",
       "19    201205.0  42.0   42.000000      36.532761\n",
       "20    201206.0   5.0    5.000000      36.555859\n",
       "21    201207.0  35.0   35.000000      35.620247\n",
       "22    201208.0  38.0   38.000000      34.071918\n",
       "23    201209.0  32.0   32.000000      32.294685\n",
       "24    201210.0  35.0   35.000000      30.723692\n",
       "25    201211.0  33.0   33.000000      29.887678\n",
       "26    201212.0  23.0   23.000000      31.419239\n",
       "27    201301.0  35.0   35.000000      29.918350\n",
       "28    201302.0  34.0   34.000000      28.477352\n",
       "29    201303.0  31.0   30.999998      28.668974\n",
       "..         ...   ...         ...            ...\n",
       "41    201403.0  32.0   32.000000      22.800194\n",
       "42    201404.0  20.0   20.000000      21.864763\n",
       "43    201405.0   0.0    0.000000      22.299210\n",
       "44    201406.0  16.0   16.000000      21.314400\n",
       "45    201407.0  25.0   25.000000      22.521513\n",
       "46    201408.0  22.0   22.000000      21.908621\n",
       "47    201409.0   5.0    5.000000      21.097118\n",
       "48    201410.0  21.0   21.000000      20.619822\n",
       "49    201411.0  30.0   30.000000      19.952507\n",
       "50    201412.0  22.0   22.000000      19.389376\n",
       "51    201501.0  28.0   28.000000      19.385174\n",
       "52    201502.0  22.0   22.000000      18.574678\n",
       "53    201503.0   0.0    0.000000      18.007071\n",
       "54    201504.0   0.0    0.000000      17.594421\n",
       "55    201505.0   3.0    3.000000      18.132944\n",
       "56    201506.0  10.0   10.000000      19.173548\n",
       "57    201507.0  24.0   24.000002      18.510143\n",
       "58    201508.0  11.0   11.000000      18.580679\n",
       "59    201509.0  27.0   27.000000      18.829767\n",
       "60    201510.0   1.0    1.000000      18.294214\n",
       "61    201511.0  10.0   10.000000      18.149229\n",
       "62    201512.0  23.0   23.000000      18.108074\n",
       "63    201601.0  24.0   24.000002      18.585575\n",
       "64    201602.0  13.0   13.000000      19.494240\n",
       "65    201603.0  20.0   20.000000      19.937077\n",
       "66    201604.0  15.0   15.000000      20.829069\n",
       "67    201605.0  24.0   24.000002      21.115686\n",
       "68    201606.0  22.0   22.000000      20.408377\n",
       "69    201607.0   6.0    6.000000      20.513691\n",
       "70    201608.0  27.0   27.000000      21.052340\n",
       "\n",
       "[71 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(inv_y_train)\n",
    "df11=df1.iloc[:,0]\n",
    "\n",
    "df2=pd.DataFrame(inv_yhat_train)\n",
    "df12=df2.iloc[:,0]\n",
    "\n",
    "df3=pd.DataFrame(np.array(master_data2.iloc[24:-n_seq,:]))\n",
    "print(df3.shape)\n",
    "df3.columns=['YearMonth','Oil']\n",
    "\n",
    "df_train=pd.concat([df3,df11,df12], axis=1)\n",
    "df_train1=pd.DataFrame(np.array(df_train))\n",
    "df_train1.columns=[\"Year-Month\",\"Oil\",\"Actual_Oil\",\"Predicted_Oil\"]\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1.to_csv('/home/affine/Downloads/Deep_Learning/demo/demo/TGS/Models/Outputs/API_42371383610000_train_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
